import os
import json
import time
import asyncio
from typing import AsyncGenerator
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import signal
import sys

from config import Config
from llm_client import LLMClient
from retriever import PaperRetriever
from idea_generator import IdeaGenerator


def load_env_file(env_file: str):
    """åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶"""
    if not os.path.isabs(env_file):
        current_dir = os.path.dirname(os.path.abspath(__file__))
        env_file = os.path.join(current_dir, env_file)
    
    if os.path.exists(env_file):
        print(f"âœ“ æ‰¾åˆ° .env æ–‡ä»¶: {env_file}")
        loaded_count = 0
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key] = value.strip('"\'')  # å»é™¤å¼•å·
                    loaded_count += 1
        print(f"âœ“ æˆåŠŸåŠ è½½ {loaded_count} ä¸ªç¯å¢ƒå˜é‡")
        return True
    else:
        print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° .env æ–‡ä»¶: {env_file}")
        return False


# åŠ è½½ç¯å¢ƒå˜é‡
load_env_file(".env")

# åˆ›å»ºFastAPIåº”ç”¨ - æ˜¾å¼æŒ‡å®šdocså’Œredocè·¯å¾„
app = FastAPI(
    title="ICAIS2025-Ideation API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# ç§»é™¤å¯èƒ½å¯¼è‡´é˜»å¡çš„è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
# ä½¿ç”¨æ›´ç®€å•çš„æ—¥å¿—è®°å½•æ–¹å¼

@app.middleware("http")
async def simple_log_middleware(request, call_next):
    """ç®€åŒ–çš„æ—¥å¿—ä¸­é—´ä»¶ï¼Œé¿å…é˜»å¡"""
    start_time = time.time()
    path = request.url.path
    
    # åªè®°å½•éå¥åº·æ£€æŸ¥çš„æ—¥å¿—ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
    if not path.startswith("/health"):
        print(f"ğŸ“¥ [{time.strftime('%H:%M:%S')}] {request.method} {path}")
    
    try:
        response = await call_next(request)
        process_time = time.time() - start_time
        if not path.startswith("/health"):
            print(f"ğŸ“¤ [{time.strftime('%H:%M:%S')}] {request.method} {path} - {response.status_code} ({process_time:.3f}s)")
        return response
    except Exception as e:
        print(f"âŒ [{time.strftime('%H:%M:%S')}] é”™è¯¯: {request.method} {path} - {e}")
        raise

# é…ç½®CORS - æ˜ç¡®è®¾ç½®originsè€Œä¸æ˜¯*
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

# è®¾ç½®å…¨å±€è¶…æ—¶
REQUEST_TIMEOUT = 600  # 10åˆ†é’Ÿè¶…æ—¶


class IdeationRequest(BaseModel):
    query: str


def format_sse_data(content: str) -> str:
    """ç”ŸæˆOpenAIæ ¼å¼çš„SSEæ•°æ®"""
    data = {
        "object": "chat.completion.chunk",
        "choices": [{
            "delta": {
                "content": content
            }
        }]
    }
    return f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

def format_sse_done() -> str:
    """ç”ŸæˆSSEç»“æŸæ ‡è®°"""
    return "data: [DONE]\n\n"

def stream_message(message: str, chunk_size: int = 1):
    """å°†æ¶ˆæ¯æŒ‰å­—ç¬¦æµå¼è¾“å‡ºï¼ˆåŒæ­¥ç”Ÿæˆå™¨ï¼‰"""
    for i in range(0, len(message), chunk_size):
        chunk = message[i:i + chunk_size]
        yield format_sse_data(chunk)


async def _generate_ideation_internal(query: str) -> AsyncGenerator[str, None]:
    """å†…éƒ¨ç”Ÿæˆå™¨å‡½æ•°ï¼Œæ‰§è¡Œå®é™…çš„ç”Ÿæˆé€»è¾‘"""
    # éªŒè¯é…ç½®ï¼ˆä¸è¾“å‡ºï¼‰
    try:
        config_valid = await asyncio.to_thread(Config.validate_config)
        if not config_valid:
            for chunk in stream_message("## âŒ é”™è¯¯\n\né…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®\n\n"):
                yield chunk
            return
    except Exception as e:
        for chunk in stream_message(f"## âŒ é”™è¯¯\n\né…ç½®éªŒè¯å¼‚å¸¸: {e}\n\n"):
            yield chunk
        return
    
    # åˆ›å»ºç»„ä»¶ï¼ˆä¸è¾“å‡ºåˆå§‹åŒ–ä¿¡æ¯ï¼‰
    try:
        client = LLMClient()
    except Exception as e:
        for chunk in stream_message(f"## âŒ é”™è¯¯\n\nLLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}\n\n"):
            yield chunk
        return
    
    try:
        retriever = PaperRetriever()
    except Exception as e:
        for chunk in stream_message(f"## âŒ é”™è¯¯\n\nè®ºæ–‡æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}\n\n"):
            yield chunk
        return
    
    # æ£€æµ‹è¯­è¨€ï¼ˆä¸è¾“å‡ºï¼‰
    language = await asyncio.to_thread(IdeaGenerator.detect_language, query)
    generator = IdeaGenerator(client, language=language)
    
    # æ­¥éª¤1: æå–å…³é”®è¯ï¼ˆç®€åŒ–è¾“å‡ºï¼‰
    keywords = await asyncio.to_thread(generator.extract_keywords, query)
    for chunk in stream_message("### ğŸ“ æ­¥éª¤ 1/9: å…³é”®è¯æå–\n\nâœ… å·²å®Œæˆ\n\n"):
        yield chunk
    
    # æ­¥éª¤2: æ‰©å±•èƒŒæ™¯ï¼ˆç®€åŒ–è¾“å‡ºï¼‰
    expanded_background = await asyncio.to_thread(generator.expand_background, query, keywords)
    for chunk in stream_message("### ğŸ” æ­¥éª¤ 2/9: èƒŒæ™¯æ‰©å±•\n\nâœ… å·²å®Œæˆ\n\n"):
        yield chunk
    
    # æ­¥éª¤3: æ··åˆæ£€ç´¢è®ºæ–‡ï¼ˆç®€åŒ–è¾“å‡ºï¼‰
    papers = await asyncio.to_thread(retriever.hybrid_retrieve, expanded_background, keywords)
    for chunk in stream_message(f"### ğŸ“š æ­¥éª¤ 3/9: è®ºæ–‡æ£€ç´¢\n\nâœ… å·²æ£€ç´¢åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡\n\n"):
        yield chunk
    
    if not papers:
        for chunk in stream_message("## âŒ é”™è¯¯\n\næœªæ£€ç´¢åˆ°ç›¸å…³è®ºæ–‡ï¼Œç¨‹åºç»ˆæ­¢\n\n"):
            yield chunk
        return
    
    # æ­¥éª¤4: Brainstormï¼ˆç®€åŒ–è¾“å‡ºï¼‰
    brainstorm = await asyncio.to_thread(generator.generate_brainstorm, expanded_background)
    for chunk in stream_message("### ğŸ’¡ æ­¥éª¤ 4/9: å¤´è„‘é£æš´\n\nâœ… å·²å®Œæˆ\n\n"):
        yield chunk
    
    # æ­¥éª¤5: å¤šæºInspirationï¼ˆç®€åŒ–è¾“å‡ºï¼‰
    inspirations = await asyncio.to_thread(
        generator.generate_multi_inspirations,
        expanded_background, query, papers
    )
    for chunk in stream_message("### âœ¨ æ­¥éª¤ 5/9: å¤šæºçµæ„Ÿç”Ÿæˆ\n\nâœ… å·²å®Œæˆ\n\n"):
        yield chunk
    
    # æ­¥éª¤6: ç”ŸæˆIdeaï¼ˆç®€åŒ–è¾“å‡ºï¼‰
    initial_ideas = await asyncio.to_thread(
        generator.generate_ideas,
        expanded_background, inspirations, brainstorm, query
    )
    for chunk in stream_message(f"### ğŸ¯ æ­¥éª¤ 6/9: åˆå§‹Ideaç”Ÿæˆ\n\nâœ… å·²ç”Ÿæˆ {len(initial_ideas)} ä¸ªåˆå§‹Idea\n\n"):
        yield chunk
    
    if not initial_ideas:
        for chunk in stream_message("## âŒ é”™è¯¯\n\næœªç”Ÿæˆä»»ä½•Ideaï¼Œç¨‹åºç»ˆæ­¢\n\n"):
            yield chunk
        return
    
    # æ­¥éª¤7: è¿­ä»£ä¼˜åŒ–ï¼ˆç®€åŒ–è¾“å‡ºï¼‰
    refined_ideas = await asyncio.to_thread(
        generator.iterative_refine_ideas,
        expanded_background, papers, initial_ideas
    )
    for chunk in stream_message(f"### ğŸ”§ æ­¥éª¤ 7/9: Ideaä¼˜åŒ–\n\nâœ… å·²ä¼˜åŒ– {len(refined_ideas)} ä¸ªIdea\n\n"):
        yield chunk
    
    # æ­¥éª¤8: è¯„ä¼°ç­›é€‰ï¼ˆä¿ç•™å…³é”®ä¿¡æ¯ï¼Œä½†ç®€åŒ–æ ¼å¼ï¼‰
    best_idea, score = await asyncio.to_thread(
        generator.evaluate_and_select_best_idea,
        expanded_background, refined_ideas
    )
    
    best_idea_clean = best_idea.strip().replace('**', '')
    for chunk in stream_message("### â­ æ­¥éª¤ 8/9: æœ€ä¼˜Ideaç­›é€‰\n\n"):
        yield chunk
    for chunk in stream_message(f"**æœ€ä¼˜Idea**:\n\n{best_idea_clean}\n\n"):
        yield chunk
    for chunk in stream_message(f"**è¯„ä¼°å¾—åˆ†**:\n\n- å¯è¡Œæ€§: {score['feasibility']:.2f}/5.0\n- åˆ›æ–°æ€§: {score['novelty']:.2f}/5.0\n- æ€»åˆ†: {score['total']:.2f}/10.0\n\n"):
        yield chunk
    
    # æ­¥éª¤9: ç”Ÿæˆç ”ç©¶è®¡åˆ’ï¼ˆå®Œæ•´è¾“å‡ºï¼‰
    for chunk in stream_message("### ğŸ“‹ æ­¥éª¤ 9/9: ç ”ç©¶è®¡åˆ’ç”Ÿæˆ\n\n"):
        yield chunk
    research_plan = await asyncio.to_thread(
        generator.generate_research_plan,
        query, papers, best_idea, inspirations["global_inspiration"]
    )
    
    # æ·»åŠ åˆ†éš”çº¿å’Œæ ‡é¢˜ï¼Œä¼˜åŒ–æ ¼å¼
    for chunk in stream_message("---\n\n"):
        yield chunk
    for chunk in stream_message("## ğŸ“„ ç ”ç©¶è®¡åˆ’\n\n"):
        yield chunk
    # å®Œæ•´è¾“å‡ºç ”ç©¶è®¡åˆ’
    for chunk in stream_message(f"{research_plan}\n\n"):
        yield chunk


async def generate_ideation_stream(query: str) -> AsyncGenerator[str, None]:
    """ç”ŸæˆIdeaçš„æµå¼è¾“å‡ºç”Ÿæˆå™¨ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼Œå…¼å®¹Python 3.9ï¼‰"""
    start_time = time.time()
    
    try:
        # æ‰§è¡Œç”Ÿæˆé€»è¾‘ï¼Œåœ¨æ¯æ¬¡ yield å‰æ£€æŸ¥è¶…æ—¶
        async for item in _generate_ideation_internal(query):
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            elapsed = time.time() - start_time
            if elapsed > REQUEST_TIMEOUT:
                for chunk in stream_message(f"## âŒ è¶…æ—¶é”™è¯¯\n\nè¯·æ±‚å¤„ç†è¶…è¿‡ {REQUEST_TIMEOUT} ç§’ï¼Œå·²è‡ªåŠ¨ç»ˆæ­¢\n\n"):
                    yield chunk
                yield format_sse_done()
                return
            yield item
        
        # å‘é€ç»“æŸæ ‡è®°
        yield format_sse_done()
                
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"âŒ ç”Ÿæˆå™¨é”™è¯¯: {e}\n{error_trace}")
        for chunk in stream_message(f"## âŒ é”™è¯¯\n\nç¨‹åºæ‰§è¡Œå¤±è´¥: {e}\n\n```\n{error_trace}\n```\n\n"):
            yield chunk
        yield format_sse_done()


@app.post("/ideation")
async def ideation(request: IdeationRequest):
    """
    Ideaç”ŸæˆAPIç«¯ç‚¹
    """
    if not request.query or not request.query.strip():
        raise HTTPException(status_code=400, detail="Query cannot be empty")
    
    return StreamingResponse(
        generate_ideation_stream(request.query),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Access-Control-Allow-Origin": "*"  # æ˜ç¡®å…è®¸SSEè·¨åŸŸ
        }
    )


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ - è½»é‡çº§å“åº”"""
    return {"status": "ok", "service": "ICAIS2025-Ideation API", "timestamp": time.time()}


@app.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "service": "ICAIS2025-Ideation API",
        "version": "1.0.0",
        "health": "http://localhost:3000/health",
        "docs": "http://localhost:3000/docs",
        "ideation": "POST /ideation"
    }


# ä¼˜é›…å…³é—­å¤„ç†
def shutdown_handler(signum, frame):
    print(f"\nâš ï¸ æ”¶åˆ°ç»ˆæ­¢ä¿¡å· {signum}ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
    sys.exit(0)


signal.signal(signal.SIGINT, shutdown_handler)
signal.signal(signal.SIGTERM, shutdown_handler)

if __name__ == "__main__":
    import uvicorn
    
    # éªŒè¯ç«¯å£å¯ç”¨æ€§
    import socket
    def check_port(port):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            try:
                s.bind(("0.0.0.0", port))
                return True
            except OSError:
                return False
    
    if not check_port(3000):
        print(f"âŒ ç«¯å£3000å·²è¢«å ç”¨ï¼Œè¯·æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æœåŠ¡åœ¨ä½¿ç”¨")
        sys.exit(1)
    
    print("ğŸš€ å¯åŠ¨ FastAPI æœåŠ¡...")
    print(f"ğŸ“ ç›‘å¬åœ°å€: http://0.0.0.0:3000")
    print(f"ğŸ“ å¥åº·æ£€æŸ¥: curl http://localhost:3000/health")
    print(f"ğŸ“š APIæ–‡æ¡£: http://localhost:3000/docs")
    
    # ä½¿ç”¨æ›´å¥å£®çš„uvicorné…ç½®
    uvicorn.run(
        app,  # ç›´æ¥ä¼ é€’appå¯¹è±¡ï¼Œå› ä¸ºappåœ¨å½“å‰æ¨¡å—ä¸­å®šä¹‰
        host="0.0.0.0",
        port=3000,
        log_level="info",
        access_log=True,
        reload=False,  # ç”Ÿäº§ç¯å¢ƒå…³é—­çƒ­é‡è½½
        workers=1,  # å•workeré¿å…å¹¶å‘é—®é¢˜
        loop="asyncio",  # æ˜ç¡®ä½¿ç”¨asyncioå¾ªç¯
        timeout_keep_alive=30,  # keep-aliveè¶…æ—¶
        limit_concurrency=100,  # é™åˆ¶å¹¶å‘æ•°
    )
